###### 編集中

## 5.0. 目的
本ブログは、**脆弱性トレンド分析システムの実装**を通して、機械学習アルゴリズムの一つである**トピックモデル**を理解する事を目的としています。  

## 5.1. 脆弱性トレンド分析
トレンド分析（Trend analysis）とは、ある観測対象から得られたデータを時系列として扱い、その**データの傾向を推定する統計手法**です。  

トレンド分析の手法は数多く存在しますが、本ブログでは**トピックモデル**と呼ばれる手法を用いてトレンド分析を行います。  

### 5.1.1. 本ブログにおけるトレンド分析のコンセプト
本ブログでは**脆弱性情報のトレンド分析**を行い、脆弱性のトレンドを推定するタスクを例とします。  

具体的には、**2018年に報告された脆弱性情報**をトピックモデルで分析し、2018年の脆弱性トレンドを可視化します。  
※分析対象の脆弱性情報は、[NVD（National Vulnerability Database）](https://nvd.nist.gov/)から取得。  

## 5.2. トピックモデル（Topic Model）入門の入門
トピックモデルは、文書に含まれるトピック（=話題）を推定する手法です。  
トピックモデルを使用することで、分析対象の文書が「**何について記述されているのか**」を知る手掛かりを得ることが可能となります。  

トピックモデルでは、文書は**幾つかのトピックで構成**されていると考え、文書を**トピックの割合**（トピック分布）で表現します。  
また、文書に含まれる各単語は、**あるトピックが持っている確率分布に従って出現**（単語分布）すると仮定します。  

このように、トピックモデルは分析対象の文書を**トピック分布と単語分布でモデル化**します。  

ここで、とある文書をトピックモデルで分析した結果、以下のトピック分布と単語分布が得られたとします。  
※()内の数値は、各トピックと単語の出現確率を表します。  

|トピック|単語|
|:--:|:--:|
| A (0.9)|シュート(0.08), スローイン(0.04), 芝(0.03), イエローカード(0.02), 守備(0.01)|
| B (0.1)|ドイツ(0.04), 人口(0.03), EURO(0.01), 子供(0.0096), ミュンヘン(0.008)|

あなたはこの分析結果を見て、とある文書は何について記述されていると思うでしょうか。  

おそらく、「サッカー」について記述されたものと考えたと思います。  
それは、文書の大部分（文書全体の90%）を占めるトピックAに、「シュート」「スローイン」「イエローカード」などの単語が多く含まれることから推測したと思います。また、文書全体の10%を占めるトピックBに、「ドイツ」「EURO」「ミュンヘン」などの単語が含まれていることから、このとある文書は「ドイツで開催されたサッカーの試合に関する記事」というように推測することができます。  

このように、トピックモデルを使用して文書を分析することで、その文書が何について記述されているのかを推定することが可能となります。  

なお、トピックモデルを実現する手法は複数存在しますが、本ブログでは**LDA**と呼ばれる手法を採用します。  

### 5.2.1. LDA（Latent Dirichlet Allocation）
LDAは自然言語処理技術の1つであり、**文書がどのようなトピックで構成されているのか分析**することが可能です。  
下図は、LDAを使用して文書を**トピック分布**と**単語分布**でモデル化した様子を示しています。  

 ![LDA概要](https://github.com/13o-bbr-bbq/machine_learning_security/blob/master/Security_and_MachineLearning/img/lda_sample.png)

トピック分布とは、文書が持つ**トピックの割合**を表したものになります。  
例えば、下図に示す文書Aは、40%の「脆弱性トピック」、50%の「生物トピック」、10%の「電車トピック」から構成されることになります。  
 
![トピック分布の概要](https://github.com/13o-bbr-bbq/machine_learning_security/blob/master/Security_and_MachineLearning/img/topic_distribution.png)  

次に、単語分布は、**各トピックが持つ単語の割合**を表したものになります。  
例えば、下図に示す脆弱性トピックは、0.3%の単語「スクリプト」、0.1%の単語「発火」、0.2%の単語「エスケープ」から構成されることになります。  
同様に生物トピックは、0.5%の単語「進化」、0.2%の単語「突然変異」、0.1%の単語「淘汰」から構成されます。  
 
![単語分布の概要](https://github.com/13o-bbr-bbq/machine_learning_security/blob/master/Security_and_MachineLearning/img/word_distribution.png)  

LDAでは、この**トピック分布と単語分布を作成するように学習**を行います。  

 ![LDAの学習](https://github.com/13o-bbr-bbq/machine_learning_security/blob/master/Security_and_MachineLearning/img/topic_learning.png)   

学習を大雑把に言うと文書にトピックを教師なし学習で割り当てるイメージとなります。[ログ分析による攻撃検知](https://github.com/13o-bbr-bbq/machine_learning_security/blob/master/Security_and_MachineLearning/Chap4_AttackDetection.md)で
この時、学習で得られたトピック分布は、**文書のトピックを強く表す**ことを意味します。  

ここで、上記の例では分かり易さを優先するために、トピックに「脆弱性」や「生物」などのラベルを付けました。しかし、**LDAは各トピックの話題を直接的に示すことはできません**。よって、LDAで作成された**トピック分布と単語分布を参考にして、人間が各トピックのラベルを推定する必要があります**。例えば、「トピック1は"スクリプト"や"発火"等といった単語の割合が多いので、これは"脆弱性トピック"」。「トピック2は"淘汰"や"進化"といった単語が多いので、これは"生物トピック"」というように推定します。  

そして最後に、**推定した各トピックを参考にして、文書が何について記述されているのかを推定**します。  

以上で、トピックモデル入門の入門は終了です。  
次節では、LDAを使用した脆弱性トレンド分析システムの構築手順と実装コードを解説します。  

## 5.3. 脆弱性トレンド分析システムの実装
本ブログでは、以下の機能を持った脆弱性トレンド分析システムを構築します。  

 1. 分析対象の文書から報告頻度が高い製品・ベンダー名や脆弱性名を抽出  
 2. 文書全体における**脆弱性のトレンドを推定**  

本システムは、NVDから取得した脆弱性情報をLDAで分析します。  
そして、報告頻度の高い対象製品・ベンダー名と脆弱性名を基に、文書全体における脆弱性のトレンドを出力します。  

### 5.3.1. 脆弱性情報の収集
分析対象の脆弱性情報を収集します。  

今回は[NVD Data Feeds](https://nvd.nist.gov/vuln/data-feeds)で公開されているFeed「CVE-2018」を使用します。このデータには、2018年に報告された脆弱性情報がCVE番号単位で収録されています。  

NVD Data Feedsから「[nvdcve-1.0-2018.json.zip](https://nvd.nist.gov/feeds/json/cve/1.0/nvdcve-1.0-2018.json.zip)」をダウンロードします。これを解凍すると、以下のようなjson形式のファイルが現れます。  

```
{
  "CVE_data_type" : "CVE",
  "CVE_data_format" : "MITRE",
  "CVE_data_version" : "4.0",
  "CVE_data_numberOfCVEs" : "15378",
  "CVE_data_timestamp" : "2019-06-19T07:06Z",
  "CVE_Items" : [ {
    "cve" : {
      "data_type" : "CVE",
      "data_format" : "MITRE",
      "data_version" : "4.0",
      "CVE_data_meta" : {
        "ID" : "CVE-2018-0001",

...snip...

      "description" : {
        "description_data" : [ {
          "lang" : "en",
          "value" : "A remote, unauthenticated attacker may be able to execute code by exploiting a use-after-free defect found in older versions of PHP through injection of crafted data via specific PHP URLs within the context of the J-Web process. Affected releases are Juniper Networks Junos OS: 12.1X46 versions prior to 12.1X46-D67; 12.3 versions prior to 12.3R12-S5; 12.3X48 versions prior to 12.3X48-D35; 14.1 versions prior to 14.1R8-S5, 14.1R9; 14.1X53 versions prior to 14.1X53-D44, 14.1X53-D50; 14.2 versions prior to 14.2R7-S7, 14.2R8; 15.1 versions prior to 15.1R3; 15.1X49 versions prior to 15.1X49-D30; 15.1X53 versions prior to 15.1X53-D70."
        } ]
      }
    },

...snip...
```

このファイルには、CVE番号（`ID`）やタイムスタンプ（`CVE_data_timestamp`）、脆弱性の詳細情報（`value`）等が含まれています。また、`value`には脆弱性の具体的な内容や対象製品等が含まれています。今回は脆弱性のトレンド分析を行いますので、上記ファイルから`value`の値（例：`A remote, unauthenticated attacker ...snip... versions prior to 15.1X53-D70.`）を取り出し、**1行=1脆弱性情報**の要領で別ファイルに書き出していきます。  

すると、以下のようなファイルが出来上がります。  

```
Buffer overflow in client/mysql.cc in Oracle MySQL and MariaDB before 5.5.35 allows remote database servers to cause a denial of service (crash) and possibly execute arbitrary code via a long server version string.
The XSLT component in Apache Camel before 2.11.4 and 2.12.x before 2.12.3 allows remote attackers to read arbitrary files and possibly have other unspecified impact via an XML document containing an external entity declaration in conjunction with an entity reference, related to an XML External Entity (XXE) issue.

...snip...


** REJECT **  DO NOT USE THIS CANDIDATE NUMBER. ConsultIDs: None.  Reason: This ID is frequently used as an example of the 2014 CVE-ID syntax change, which allows more than 4 digits in the sequence number. Notes: See references.
** REJECT **  DO NOT USE THIS CANDIDATE NUMBER. ConsultIDs: None.  Reason: This ID is frequently used as an example of the 2014 CVE-ID syntax change, which allows more than 4 digits in the sequence number. Notes: See references.
```

ここで、NVDには「DISPUTED」や「REJECT」等のラベルが付与された脆弱性情報が存在する事が分かります。これらは他のCVE番号への統合や係争中等の理由により、将来削除される可能性がある、または既に削除されているものです。よって、これらの情報は分析に寄与しないため削除しておきます。  

この処理を施した結果を、「[cve2018.csv](https://github.com/13o-bbr-bbq/machine_learning_security/blob/master/Security_and_MachineLearning/dataset/topic_model/cve2018.csv)」として保存します。  

### 5.3.2. 脆弱性名と製品名の加工
LDAでは **単語の出現頻度を基に単語分布を作成**します。よって、`Buffer overflow`や`Content Type`等のように**複数単語の組み合わせで意味を持つ**単語の場合、`Buffer`と`overflow`というように分かれて単語分布が作成されると、真のトピックが求められなくなる可能性があります。  

そこで、複数単語の組み合わせで意味を持つ単語は、単語間の空白をアンダースコア「\_」で置換しておきます。  
以下に一例を示します。  

| 置換前|置換後|
|:------|:------|
| Buffer overflow|Buffer_overflow|
| XML External Entity|XML_External_Entity|
| cross site request forgery|cross_site_request_forgery|
| Content Type|Content_Type|
| Word Press|Word_Press|
| Internet Explorer|Internet_Explorer|

### 5.3.3. ストップワードの定義
[2章 スパム検知](https://github.com/13o-bbr-bbq/machine_learning_security/blob/master/Security_and_MachineLearning/Chap2_SpamDetection.md)でも述べたように、自然言語処理では分析に寄与しないストップワードを削除する必要があるため、以下のルールでストップワードリストを定義します。  

 * 英語としてありふれた単語  
 * セキュリティ的にありふれた単語  

前者は、（後述する）scikit-learnにデフォルトで実装されているストップワードリストを使用します。  
一方、後者は自作する必要があります。今回の分析対象は「CVE情報の塊」となるため、CVE情報特有のストップワードを定義します。  

以下に自作したストップワードリストの一例を示します。  

```
earlier
prior
before
after
version

...snip...

vulnerability
attacker
user
attack
```

CVE情報には脆弱性の影響を受ける製品バージョンの範囲を示す「earlier」「prior」、攻撃の主体や被害者を示す「attacker」「user」等の単語が多く含まれます。このような、脆弱性情報（=セキュリティ的にありふれた単語）をストップワードとして定義し、分析の対象外とします。  

このオリジナルのストップワードを纏めたファイルを「[stop_words.txt](https://github.com/13o-bbr-bbq/machine_learning_security/blob/master/Security_and_MachineLearning/dataset/topic_model/stop_words.txt)」として保存します。  

これで、分析の準備が整いました。  
次節では実際にサンプルコードを実行し、年毎に脆弱性のトレンド分析が行えるのか検証します。  

## 5.4. サンプルコード及び実行結果
### 5.4.1. サンプルコード
本ブログではPython3を使用し、簡易的な脆弱性トレンド分析システムを実装しました。  
※本コードは[こちら](https://github.com/13o-bbr-bbq/machine_learning_security/blob/master/Security_and_MachineLearning/src/topic_model.py)から入手できます。  

本システムの大まかな処理フローは以下のとおりです。  

 1. ストップワードリストのロード  
 2. 分析対象文書のロード  
 3. 文書からストップワードの除外  
 4. LDAによるトレンド分析  
 5. 分析結果の出力  

```
#!/bin/env python
# -*- coding: utf-8 -*-
import os
import random
import pandas as pd
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.decomposition import LatentDirichletAllocation

# Parameters of LDA
n_samples = 100000
n_topics = 5
n_top_words = 20


# Output topic and topic words
def print_top_words(model, feature_names):
    for topic_idx, topic in enumerate(model.components_):
        message = 'Topic #{}: '.format(topic_idx + 1)
        message += ' '.join([feature_names[i] for i in topic.argsort()[:-n_top_words - 1:-1]])
        print(message)


if __name__ == '__main__':
    full_path = os.path.dirname(os.path.abspath(__file__))
    root_path = os.path.join(full_path, '..')

    # Get original stop words
    dataset_path = os.path.join(os.path.join(root_path, 'dataset'), 'topic_model')
    stop_word_path = os.path.join(dataset_path, 'stop_words.txt')
    df_stop_words = pd.read_csv(stop_word_path, encoding='utf-8').fillna('')
    data_samples = df_stop_words.loc[:].values
    lst_stop_words = [word[0] for word in data_samples.tolist()]

    # Load cve description
    lst_cve_description = []
    for file in os.listdir(dataset_path):
        # extract description from 'cve****.txt'
        if file[:3] == 'cve' and file[-4:] == '.csv':
            df_cve = pd.read_csv(os.path.join(dataset_path, file), encoding='utf-8').fillna('')
            data_samples = df_cve.loc[random.sample(range(len(df_cve)), n_samples)].values
            lst_cve_description = [description[0] for description in data_samples.tolist()]
        else:
            continue

        # Remove stop words
        lst_bow = []
        for description in lst_cve_description:
            temp_description = ''
            for word in description.split(' '):
                if not word in lst_stop_words:
                    temp_description += word + ' '
            lst_bow.append(temp_description)

        # Use tf (raw term count) features for LDA (Latent Dirichlet Allocation).
        tf_vectorizer = CountVectorizer(stop_words='english')
        tf = tf_vectorizer.fit_transform(lst_bow)
        lda = LatentDirichletAllocation(n_components=n_topics, max_iter=20)
        lda.fit(tf)

        # Output result
        print('#'*50)
        print('Topics in LDA model from ' + file)
        print('#'*50)
        tf_feature_names = tf_vectorizer.get_feature_names()
        print_top_words(lda, tf_feature_names)
        print('')

    print('finish!!')
```

### 5.4.2. コード解説
今回はLDAの実装に、機械学習ライブラリの**scikit-learn**を使用しました。  
※scikit-learnの使用方法は[公式ドキュメント](http://scikit-learn.org/)を参照のこと。  

##### パッケージのインポート
```
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.decomposition import LatentDirichletAllocation
```

scikit-learnのLDAパッケージ「`LatentDirichletAllocation`」をインポートします。  
このパッケージには、LDAを扱うための様々なクラスが収録されています。  

また、分析対象文書のベクトル化に使用するパッケージ「`CountVectorizer`」も併せてインポートします。  
ベクトル化された文書は、LDAでトレンド分析する際に使用します。  

##### ストップワードの取得
```
# Get original stop words
dataset_path = os.path.join(os.path.join(root_path, 'dataset'), 'topic_model')
stop_word_path = os.path.join(dataset_path, 'stop_words.txt')
df_stop_words = pd.read_csv(stop_word_path, encoding='utf-8').fillna('')
data_samples = df_stop_words.loc[:].values
lst_stop_words = [word[0] for word in data_samples.tolist()]
```

ストップワードリスト「`stop_words.txt`」から、ストップワードを取得しリスト化します。  

##### CVE情報の取得
```
# Load cve description
lst_cve_description = []
for file in os.listdir(dataset_path):
    # extract description from 'cve****.txt'
    if file[:3] == 'cve' and file[-4:] == '.csv':
        df_cve = pd.read_csv(os.path.join(dataset_path, file), encoding='utf-8').fillna('')
        data_samples = df_cve.loc[random.sample(range(len(df_cve)), n_samples)].values
        lst_cve_description = [description[0] for description in data_samples.tolist()]
    else:
        continue
```

ディレクトリ「`topic_model`」に配置されたCVE情報「`cve2018.csv`」を読み込み、脆弱性情報単位にリスト化します。  

##### ストップワードの除外と単語リストの作成
```
# Remove stop words
lst_bow = []
for description in lst_cve_description:
    temp_description = ''
    for word in description.split(' '):
        if not word in lst_stop_words:
            temp_description += word + ' '
    lst_bow.append(temp_description)
```

リスト化したCVE情報を単語単位に分割し、単語がストップワードリストに含まれるかチェックします。  
そして、ストップワードではない単語のみをリスト化します。  

##### 文書のベクトル化
```
tf_vectorizer = CountVectorizer(stop_words='english')
tf = tf_vectorizer.fit_transform(lst_bow)
```

`CountVectorizer`を使用して文書に含まれる単語の出現回数を基にベクトル化します。  
`CountVectorizer`の引数に`stop_words='english'`を指定することで、`CountVectorizer`標準の英語ストップワードを除外することができます。  
※`CountVectorizer`の詳細説明は[公式ドキュメント](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html)を参照のこと。  

作成したモデル`tf_vectorizer`の`fit_transform`に引数として単語リスト`lst_bow`を渡すことで、CVE情報をベクトル化します。  

##### LDAによるトレンド分析
```
lda = LatentDirichletAllocation(n_components=n_topics, max_iter=20)
lda.fit(tf)
```

`LatentDirichletAllocation`を使用して脆弱性のトレンド分析を行います。  
※`LatentDirichletAllocation`の詳細説明は[公式ドキュメント](http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html)を参照のこと。  

作成したLDAモデル`lda`の`fit`に引数としてベクトル化したCVE情報`tf`を渡すことで、LDAによるトレンド分析が実行されます。  

##### 分析結果の出力
```
# Output result
print('#'*50)
print('Topics in LDA model from ' + file)
print('#'*50)
tf_feature_names = tf_vectorizer.get_feature_names()
print_top_words(lda, tf_feature_names)
print('')
```

トレンド分析の結果を、「トピック＋トピックを構成する単語リスト」の形式で出力します。  
なお、トピック数は5（`n_topics = 5`）、トピック毎の単語数は20（`n_top_words = 20`）に設定しています。  

### 5.4.3. 実行結果
それでは早速実行してみましょう。  

```
PS C:\Security_and_MachineLearning\src> python topic_model.py
```

実行すると、以下の結果が得られます。  

```
##################################################
Topics in LDA model from cve2018.csv
##################################################
Topic #1: mobile snapdragon iot industrial consumer snapdragon_high_med_ music voice buffer_overflow electronics wearables wear automobile qualcomm denial_of_service stack ipq buffer improper infrastructure
Topic #2: execute_code adobe information_disclosure acrobat_reader out_of_bounds big ip xss firefox memory_corruption engine esr thunderbird elevation_of_privilege microsoft_edge use free android command internet_explorer
Topic #3: denial_of_service disclosure channel systems microprocessors cameras cisco axis ids oracle bypass memory_corruption platform branch core command server zoho ui services
Topic #4: force ibm controller spectrum flashsystem san storwize intel management engine converged active technology information_disclosure manageability session denial_of_service xss buffer_overflow disclosure
Topic #5: denial_of_service windows server execute_code juniper_networks junos_os microsoft ios domain servers message cisco database internal buffer_overflow information_disclosure elevation_of_privilege qfabric non corrupt
```

2018年の脆弱性情報における**5つのトピック**（Topic \#1 ～ Topic \#5）が抽出され、**各トピックを代表する（出現頻度が高い）上位20個の単語**が出力されている事が分かります。それでは、各トピックの単語を一つずつ見ながら、2018年に話題になった脆弱性名や製品・ベンダー名を見ていきましょう。  

#### Topic #1
```
Topic #1: mobile snapdragon iot industrial consumer snapdragon_high_med_ music voice buffer_overflow electronics wearables wear automobile qualcomm denial_of_service stack ipq buffer improper infrastructure
```

本トピックには、`snapdragon`や`qualcom`、`buffer_overflow`や`denial_of_service`等の単語が含まれていることから、本トピックはQualcom社SnapDragonにBoFやDoSの脆弱性が存在することを示唆するトピックであると推定できます。なお、本製品はモバイル端末向けのCPUであるため、`mobile`や`wearables`、`wear`等の単語が含まれているのも納得できます。  

実際に2018年の脆弱性情報を検索してみると、`SnapDragon`に関連する脆弱性情報は**約8,000件**見つかります。これは、脆弱性情報全体（≒100,000）の**8パーセント**に相当する量となります。また、報告された脆弱性情報の多くはBoFとDoSであるため、概ねトピック分析の結果と一致していることが分かります。  

#### Topic #2
```
Topic #2: execute_code adobe information_disclosure acrobat_reader out_of_bounds big ip xss firefox memory_corruption engine esr thunderbird elevation_of_privilege microsoft_edge use free android command internet_explorer
```

本トピックには、`adobe`や`acrobat_reader`、`firefox`等の単語が含まれています。また、`execute_code`や`information_disclosure`、`xss`等も含まれています。このことから、本トピックはAdobe社Acrobat ReaderとMozzila Firefoxに任意のコード実行や意図しない情報開示、XSSなどの脆弱性が存在することを示唆するトピックであると推定できます。  

実際に2018年の脆弱性情報を検索してみると、`Acrobat Reader`に関連する脆弱性情報は**約3,500件**見つかります。また、`Firefox`に関連する脆弱性情報は`約1,800件`見つかります。この総計は、脆弱性情報全体（≒100,000）の**5.3パーセント**に相当する量となります。また、報告された脆弱性情報の多くは任意のコード実行や意図しない情報開示などであるため、概ねトピック分析の結果と一致していることが分かります。  

#### Topic #3
```
Topic #3: denial_of_service disclosure channel systems microprocessors cameras cisco axis ids oracle bypass memory_corruption platform branch core command server zoho ui services
```

本トピックには、`cisco`や`axis`、`cameras`や`denial_of_service`等も含まれています。このことから、本トピックはCISCO社の何らかの製品（今回の分析では明らかにならなかった）とAXIS社のネットワークカメラにDoSの脆弱性が存在することを示唆するトピックであると推定できます。  

実際に2018年の脆弱性情報を検索してみると、`CISCO`に関連する脆弱性情報は**約6,100件**見つかります。また、`Axis`に関連する脆弱性情報は**約5,500件**見つかります。この総計は、脆弱性情報全体（≒100,000）の**11.6パーセント**に相当する量となります。また、報告された脆弱性情報の多くはDoSであるため、概ねトピック分析の結果と一致していることが分かります。  

#### Topic #4
```
Topic #4: force ibm controller spectrum flashsystem san storwize intel management engine converged active technology information_disclosure manageability session denial_of_service xss buffer_overflow disclosure
```

本トピックには、`ibm`や`spectrum`、`flashsystem`、`storwize`や、`information_disclosure`、`denial_of_service`、`buffer_overflow`、`xss`等も含まれています。このことから、本トピックはIBM社Spectrum・FlashSystem・Storwizeといったストレージ製品に意図しない情報開示やDoS、BoF、XSSなどの脆弱性が存在することを示唆するトピックであると推定できます。  

実際に2018年の脆弱性情報を検索してみると、`IBM`に関連する脆弱性情報は**約10,700件**見つかります。これは、脆弱性情報全体（≒100,000）の**10.7パーセント**に相当する量となります。また、報告された脆弱性情報の多くは意図しない情報開示、DoS、BoF、XSSであるため、概ねトピック分析の結果と一致していることが分かります。  

#### Topic #5
```
Topic #5: denial_of_service windows server execute_code juniper_networks junos_os microsoft ios domain servers message cisco database internal buffer_overflow information_disclosure elevation_of_privilege qfabric non corrupt
```

本トピックには、`windows`や`juniper_networks`、`junos_os`等が含まれています。また、`denial_of_service`や`execute_code`、`buffer_overflow`等も含まれています。このことから、本トピックはMicrosoft社WindowsやJuniper Networks社JUNOSにDoSや任意のコード実行、BoFの脆弱性が存在することを示唆するトピックであると推定できます。  

実際に2018年の脆弱性情報を検索してみると、`Windows`に関連する脆弱性情報は**約6,000件**見つかります。また、`JUNOS`に関連する脆弱性情報は**約4,700件**見つかります。この総計は、脆弱性情報全体（≒100,000）の**10.7パーセント**に相当する量となります。また、報告された脆弱性情報の多くはDoSや任意のコード実行、BoFであるため、概ねトピック分析の結果と一致していることが分かります。  

## 5.5. おわりに

## 5.5. 動作条件
 * Python 3.6.1（Anaconda3）
 * pandas 0.20.3
 * scikit-learn 0.19.0
