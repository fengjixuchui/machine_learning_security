###### 編集中

## 5.0. 目的
本ブログは、**脆弱性トレンド分析システムの実装**を通して、機械学習アルゴリズムの一つである**トピックモデル**を理解する事を目的としています。  

## 5.1. 脆弱性トレンド分析
トレンド分析（Trend analysis）とは、ある観測対象から得られたデータを時系列として扱い、そのデータの傾向を推定する統計手法です。  

トレンド分析の手法は数多く存在しますが、本ブログでは**トピックモデル**と呼ばれる手法を用いてトレンド分析を行います。  

### 5.1.1. 本ブログにおけるトレンド分析のコンセプト
本ブログでは**脆弱性情報のトレンド分析**を行い、脆弱性トレンドの移り変わりを分析するタスクを例とします。

具体的には、（本執筆時点における）**昨年（2018年）報告された脆弱性情報**を分析し、2018年の脆弱性トレンドを可視化します。そして、これをトピックモデルで実装します。なお、これを行うためには2018年の脆弱性情報が必要になりますが、今回は[NVD（National Vulnerability Database）](https://nvd.nist.gov/)から提供される脆弱性情報を利用します。  

## 5.2. トピックモデル（Topic Model）入門の入門
トピックモデルは、文書の背後に隠れたトピック（話題）を推定する手法であり、文書が複数の**潜在的なトピックから確率的に生成**されると仮定したモデルです。また、文書内の各単語は、**あるトピックが持つ確率分布に従って出現**すると仮定します。  

このようにトピックモデルを使用することで、**文書のトピック分布と単語分布を得る事ができる**ため、その文書が**何について記述**されているのかを推定することが可能となります。  

ここで、トピックモデルを実現する手法は複数存在しますが、本ブログでは**LDA（Latent Dirichlet Allocation）**と呼ばれる手法を採用します。  

### 5.2.1. LDA（Latent Dirichlet Allocation）
LDAは自然言語処理技術の1つであり、文書がどのようなトピックで構成されているのかを分析することが可能です。下図は、LDAを使用して文書を**トピック分布**と**単語分布**でモデル化した様子を示しています。  

 ![LDA概要](https://github.com/13o-bbr-bbq/machine_learning_security/blob/master/Security_and_MachineLearning/img/lda_sample.png)

 * トピック分布  
 トピック分布は、文書が持つトピックの割合を表したもの。　　
 上図では、脆弱性トピックは40%、生物トピックは50%、電車トピックは10%等となる。  

 * 単語分布  
 単語分布は、トピックが持つ単語の割合を表したもの。  
 上図では、脆弱性トピック内の単語「スクリプト」は0.3%、「発火」は0.1%、「エスケープ」は0.2%等となる。  

このように、分析対象の文書をLDAに学習させることで、文書のトピック分布と各トピックの単語分布を求める事ができます。言わば、**学習で得られたトピック分布は文書の話題を強く表す**事を意味します。  

ここで、上記の例では分かり易さを優先して、トピックに「脆弱性」や「生物」等の名前を付けました。しかし、**LDAは各トピックの話題を直接的に示すことはできません**。よって、[4章 ログ分析による攻撃検知クラスタリング](https://github.com/13o-bbr-bbq/machine_learning_security/blob/master/Security_and_MachineLearning/Chap4_AttackDetection.md)と同じく、**LDAが求めたトピック分布と単語分布を参考に、人間が「トピック1は"スクリプト"や"発火"等といった単語の割合が多いので、脆弱性トピック。」「トピック2は"淘汰"や"進化"等といった単語の割合が多いので、生物トピック。」というように推定する必要があります。そして、推定した各トピックを基に、文書自体が何について記述されているのかを推定する必要があります。  

以上で、トピックモデル入門の入門は終了です。  
次節では、LDAを使用した脆弱性トレンド分析システムの構築手順と実装コードを解説します。  

## 5.3. 脆弱性トレンド分析システムの実装
本ブログでは、以下の機能を持った脆弱性トレンド分析システムを構築します。  

 1. 報告回数の多い**脆弱性名**と**対象製品**を抽出  
 2. 2018年における、1のトレンドを出力  

本システムは、CVE番号が付与された大量の脆弱性情報をLDAで分析します。  
そして、報告回数の多い脆弱性名と対象製品から2018年における脆弱性のトレンドを出力します。  

### 5.3.1. 脆弱性情報の収集
分析対象の脆弱性情報を収集します。  

今回は[NVD Data Feeds](https://nvd.nist.gov/vuln/data-feeds)で公開されているFeed「CVE-2018」を使用します。このデータには、各毎の脆弱性情報がCVE番号単位で含まれています。  

NVD Data Feedsから「[nvdcve-1.0-2018.json.zip](https://nvd.nist.gov/feeds/json/cve/1.0/nvdcve-1.0-2018.json.zip)」をダウンロードします。このファイルを解凍すると、以下のようなjson形式のファイルが現れます。  

```
{
  "CVE_data_type" : "CVE",
  "CVE_data_format" : "MITRE",
  "CVE_data_version" : "4.0",
  "CVE_data_numberOfCVEs" : "15378",
  "CVE_data_timestamp" : "2019-06-19T07:06Z",
  "CVE_Items" : [ {
    "cve" : {
      "data_type" : "CVE",
      "data_format" : "MITRE",
      "data_version" : "4.0",
      "CVE_data_meta" : {
        "ID" : "CVE-2018-0001",

...snip...

      "description" : {
        "description_data" : [ {
          "lang" : "en",
          "value" : "A remote, unauthenticated attacker may be able to execute code by exploiting a use-after-free defect found in older versions of PHP through injection of crafted data via specific PHP URLs within the context of the J-Web process. Affected releases are Juniper Networks Junos OS: 12.1X46 versions prior to 12.1X46-D67; 12.3 versions prior to 12.3R12-S5; 12.3X48 versions prior to 12.3X48-D35; 14.1 versions prior to 14.1R8-S5, 14.1R9; 14.1X53 versions prior to 14.1X53-D44, 14.1X53-D50; 14.2 versions prior to 14.2R7-S7, 14.2R8; 15.1 versions prior to 15.1R3; 15.1X49 versions prior to 15.1X49-D30; 15.1X53 versions prior to 15.1X53-D70."
        } ]
      }
    },

...snip...
```

このファイルには、CVE番号（`ID`）やタイムスタンプ（`CVE_data_timestamp`）、脆弱性の詳細情報（`value`）等が含まれています。また、`value`には脆弱性の具体的な内容や対象製品等が含まれています。今回は脆弱性のトレンド分析を行いますので、上記ファイルから`value`の値（例：A remote, unauthenticated attacker ...snip... versions prior to 15.1X53-D70.）を取り出し、「1行1脆弱性」の要領で別ファイルに書き出していきます。  

すると、以下のようなファイルが出来上がります。  

```
Buffer overflow in client/mysql.cc in Oracle MySQL and MariaDB before 5.5.35 allows remote database servers to cause a denial of service (crash) and possibly execute arbitrary code via a long server version string.
The XSLT component in Apache Camel before 2.11.4 and 2.12.x before 2.12.3 allows remote attackers to read arbitrary files and possibly have other unspecified impact via an XML document containing an external entity declaration in conjunction with an entity reference, related to an XML External Entity (XXE) issue.

...snip...


** REJECT **  DO NOT USE THIS CANDIDATE NUMBER. ConsultIDs: None.  Reason: This ID is frequently used as an example of the 2014 CVE-ID syntax change, which allows more than 4 digits in the sequence number. Notes: See references.
** REJECT **  DO NOT USE THIS CANDIDATE NUMBER. ConsultIDs: None.  Reason: This ID is frequently used as an example of the 2014 CVE-ID syntax change, which allows more than 4 digits in the sequence number. Notes: See references.
```

ここで、NVDには「DISPUTED」や「REJECT」等のラベルが付与された脆弱性情報が存在する事が分かります。これらは他のCVE番号への統合や係争中等の理由により、将来削除される可能性がある、または既に削除されているものです。よって、これらの情報はノイズになるため、ファイルから削除しておきます。  

この処理を施した結果を、「[cve2018.txt](https://github.com/13o-bbr-bbq/machine_learning_security/blob/master/Security_and_MachineLearning/dataset/topic_model/cve2018.txt)」として保存します。  

### 5.3.2. 脆弱性名と製品名の加工
LDAでは **単語の出現頻度を基に単語分布を作成**します。よって、`Buffer overflow`や`Content Type`等のように**複数単語の組み合わせで意味を持つ**単語の場合、`Buffer`と`overflow`等と分けて単語分布が作成されると、真のトピックが求められなくなる可能性があります。  

そこで、複数単語の組み合わせで意味を持つ単語は、単語間の空白をアンダースコア「\_」で置換しておきます。  
以下に一例を示します。  

| 置換前|置換後|
|:------|:------|
| Buffer overflow|Buffer_overflow|
| XML External Entity|XML_External_Entity|
| cross site request forgery|cross_site_request_forgery|
| Content Type|Content_Type|
| Word Press|Word_Press|
| Internet Explorer|Internet_Explorer|

### 5.3.3. ストップワードの定義
[2章 スパム検知](https://github.com/13o-bbr-bbq/machine_learning_security/blob/master/Security_and_MachineLearning/Chap2_SpamDetection.md)でも述べたように、自然言語処理では分析に寄与しないストップワードを削除する必要があるため、以下のルールでストップワードリストを定義します。  

 * 英語としてありふれた単語  
 * セキュリティ的にありふれた単語  

前者は、（後述する）scikit-learnにデフォルトで実装されているストップワードリストを使用します。  
一方、後者は自作する必要があります。今回の分析対象は「CVE情報の塊」となるため、CVE情報特有のストップワードを定義します。  

以下に自作したストップワードリストの一例を示します。  

```
earlier
prior
before
after
version

...snip...

vulnerability
attacker
user
attack

```

CVE情報には脆弱性の影響を受ける製品バージョンの範囲を示す「earlier」「prior」、攻撃の主体や被害者を示す「attacker」「user」等の単語が多く含まれます。このような、脆弱性情報では「ありふれた単語」をストップワードとして定義し、分析の対象外とします。  

このストップワードを纏めたファイルを「[stop_words.txt](https://github.com/13o-bbr-bbq/machine_learning_security/blob/master/Security_and_MachineLearning/dataset/topic_model/stop_words.txt)」として保存します。  

これで、分析の準備が整いました。  
次節では実際にサンプルコードを実行し、年毎に脆弱性のトレンド分析が行えるのか検証します。  

## 5.4. サンプルコード及び実行結果
### 5.4.1. サンプルコード
本ブログではPython3を使用し、簡易的な脆弱性トレンド分析システムを実装しました。  
※本コードは[こちら]()から入手できます。  

本システムの大まかな処理フローは以下のとおりです。  

 1. ストップワードリストのロード  
 2. 分析対象文書のロード  
 3. 文書からストップワードの除外  
 4. LDAによるトレンド分析  
 5. 分析結果の出力  

```
#!/bin/env python
# -*- coding: utf-8 -*-
import os
import random
import pandas as pd
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.decomposition import LatentDirichletAllocation

# Parameters of LDA
n_samples = 7000
n_features = 50
n_topics = 5
n_top_words = 10
max_df = 0.95
min_df = 10


# Output topic and topic words
def print_top_words(model, feature_names):
    for topic_idx, topic in enumerate(model.components_):
        message = 'Topic #{0}: '.format(topic_idx)
        message += ' '.join([feature_names[i] for i in topic.argsort()[:-n_top_words - 1:-1]])
        print(message)


if __name__ == '__main__':
    # Get original stop words
    df_stop_words = pd.read_csv('..\\dataset\\topic_model\\stop_words.txt', encoding='utf-8').fillna('')
    data_samples = df_stop_words.loc[:].values
    lst_stop_words = [word[0] for word in data_samples.tolist()]

    # Load cve description
    lst_cve_description = []
    for file in os.listdir('..\\dataset\\topic_model\\'):
        # extract description from 'cve****.txt'
        if file[:3] == 'cve' and file[-4:] == '.txt':
            df_cve = pd.read_csv('..\\dataset\\topic_model\\' + file, encoding='utf-8').fillna('')
            data_samples = df_cve.loc[random.sample(range(len(df_cve)), n_samples)].values
            lst_cve_description = [description[0] for description in data_samples.tolist()]
        else:
            continue

        # Remove stop words
        lst_bow = []
        for description in lst_cve_description:
            temp_description = ''
            for word in description.lower().split(' '):
                if not word in lst_stop_words:
                    temp_description += word + ' '
            lst_bow.append(temp_description)

        # Use tf (raw term count) features for LDA (Latent Dirichlet Allocation).
        tf_vectorizer = CountVectorizer(max_df=max_df, min_df=min_df,
                                        max_features=n_features,
                                        stop_words='english')
        tf = tf_vectorizer.fit_transform(lst_bow)
        lda = LatentDirichletAllocation(n_components=n_topics, max_iter=5,
                                        learning_method='online',
                                        learning_offset=50.,
                                        random_state=0)
        lda.fit(tf)

        # Output result
        print('#'*50)
        print('Topics in LDA model from ' + file)
        print('#'*50)
        tf_feature_names = tf_vectorizer.get_feature_names()
        print_top_words(lda, tf_feature_names)
        print('')

    print('finish!!')
```

### 5.4.2. コード解説
今回はLDAの実装に、機械学習ライブラリの**scikit-learn**を使用しました。  
※scikit-learnの使用方法は[公式ドキュメント](http://scikit-learn.org/)を参照のこと。  

##### パッケージのインポート
```
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.decomposition import LatentDirichletAllocation
```

scikit-learnのLDAパッケージ「`LatentDirichletAllocation`」をインポートします。  
このパッケージには、LDAを扱うための様々なクラスが収録されています。  

また、分析対象文書のベクトル化に使用するパッケージ「`CountVectorizer`」も併せてインポートします。  
ベクトル化された文書は、LDAでトレンド分析する際に使用します。  

##### ストップワードの取得
```
df_stop_words = pd.read_csv('..\\dataset\\topic_model\\stop_words.txt', encoding='utf-8').fillna('')
data_samples = df_stop_words.loc[:].values
lst_stop_words = [word[0] for word in data_samples.tolist()]
```

ストップワードリスト「`stop_words.txt`」から、ストップワードを取得しリスト化します。  

##### CVE情報の取得
```
lst_cve_description = []
for file in os.listdir('..\\dataset\\topic_model\\'):
    # extract description from 'cve****.txt'
    if file[:3] == 'cve' and file[-4:] == '.txt':
        df_cve = pd.read_csv('..\\dataset\\topic_model\\' + file, encoding='utf-8').fillna('')
        data_samples = df_cve.loc[random.sample(range(len(df_cve)), n_samples)].values
        lst_cve_description = [description[0] for description in data_samples.tolist()]
    else:
        continue
```

ディレクトリ「`topic_model`」に配置された年度毎のCVE情報「`cve2014.txt`」「`cve2015.txt`」「`cve2016.txt`」を1ファイルずつ読み込み、脆弱性情報単位にリスト化します。  

##### ストップワードの除外と単語リストの作成
```
lst_bow = []
for description in lst_cve_description:
    temp_description = ''
    for word in description.lower().split(' '):
        if not word in lst_stop_words:
            temp_description += word + ' '
    lst_bow.append(temp_description)
```

リスト化したCVE情報を単語単位に分割し、単語がストップワードリストに含まれるかチェックします。  
そして、ストップワードではない単語のみをリスト化します。  

##### 文書のベクトル化
```
tf_vectorizer = CountVectorizer(max_df=max_df, min_df=min_df,
                                max_features=n_features,
                                stop_words='english')
tf = tf_vectorizer.fit_transform(lst_bow)
```

`CountVectorizer`を使用して文書に含まれる単語の出現回数を基にベクトル化します。  
`CountVectorizer`の引数に`stop_words='english'`を指定することで、`CountVectorizer`標準の英語ストップワードを除外することができます。  
※`CountVectorizer`の詳細説明は[公式ドキュメント](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html)を参照のこと。  

作成したモデル`tf_vectorizer`の`fit_transform`に引数として単語リスト`lst_bow`を渡すことで、CVE情報をベクトル化します。  

##### LDAによるトレンド分析
```
lda = LatentDirichletAllocation(n_components=n_topics, max_iter=5,
                                learning_method='online',
                                learning_offset=50.,
                                random_state=0)
lda.fit(tf)
```

`LatentDirichletAllocation`を使用して脆弱性のトレンド分析を行います。  
※`LatentDirichletAllocation`の詳細説明は[公式ドキュメント](http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html)を参照のこと。  

作成したLDAモデル`lda`の`fit`に引数としてベクトル化したCVE情報`tf`を渡すことで、LDAによるトレンド分析が実行されます。  

##### 分析結果の出力
```
print('#'*50)
print('Topics in LDA model from ' + file)
print('#'*50)
tf_feature_names = tf_vectorizer.get_feature_names()
print_top_words(lda, tf_feature_names)
print('')
```

トレンド分析の結果を、年度毎に「トピック＋トピックを構成する単語リスト」の形式で出力します。  
なお、年度毎のトピック数は5、トピック毎の単語数は10に設定しています。  

### 5.4.3. 実行結果
それでは早速実行してみましょう。  

```
PS C:\Security_and_MachineLearning\src> python topic_model.py
```

実行すると、以下の結果が得られます。  

```
##################################################
Topics in LDA model from cve2014.txt
##################################################
Topic #0: access windows adobe_air execute cisco manager ibm bug request sql_injection
Topic #1: android certificate ssl spoof man_in_the_middle verify certificates com java integrity
Topic #2: denial_of_service code_execution crash internet_explorer files read site buffer_overflow ibm possibly
Topic #3: unknown possibly kernel privileges authentication gain impact bypass linux denial_of_service
Topic #4: php parameter xss cross_site_scripting script inject multiple plugin wordpress admin

##################################################
Topics in LDA model from cve2015.txt
##################################################
Topic #0: windows bypass privileges access sp2 sp1 gain r2 gold leveraging
Topic #1: denial_of_service code_execution crash site internet_explorer possibly impact devices buffer_overflow ios
Topic #2: xss php cross_site_scripting script parameter inject cisco execute bug commands
Topic #3: adobe_air sdk linux windows code_execution adobe flash_player adobe_reader acrobat kernel
Topic #4: unknown files ibm java manager read authentication request management access

##################################################
Topics in LDA model from cve2016.txt
##################################################
Topic #0: android bug xss script linux cross_site_scripting devices inject internal cisco
Topic #1: ibm acrobat adobe_reader dc windows code_execution denial_of_service cross_site_scripting bypass devices
Topic #2: access confidentiality manager integrity files bypass process android http malicious
Topic #3: denial_of_service code_execution crash impact buffer_overflow possibly discovered ios affected site
Topic #4: windows sp1 sp2 privileges php out_of_bounds gain leveraging gold read
```

年毎に5つのトピック（Topic \#0 ～ Topic \#4）が抽出され、各トピックを代表する上位10個の単語が出力されている事が分かります。それでは、各トピックの単語を一つずつ見ながら、各年で話題になった脆弱性や製品を見ていきましょう。  

#### 2014年の脆弱性トレンド
```
##################################################
Topics in LDA model from cve2014.txt
##################################################
Topic #0: access windows adobe_air execute cisco manager ibm bug request sql_injection
Topic #1: android certificate ssl spoof man_in_the_middle verify certificates com java integrity
Topic #2: denial_of_service code_execution crash internet_explorer files read site buffer_overflow ibm possibly
Topic #3: unknown possibly kernel privileges authentication gain impact bypass linux denial_of_service
Topic #4: php parameter xss cross_site_scripting script inject multiple plugin wordpress admin
```

https://www.cvedetails.com/vulnerability-list/vendor_id-53/product_id-11602/year-2014/Adobe-Adobe-Air.html

#### 2015年の脆弱性トレンド
```
##################################################
Topics in LDA model from cve2015.txt
##################################################
Topic #0: windows bypass privileges access sp2 sp1 gain r2 gold leveraging
Topic #1: denial_of_service code_execution crash site internet_explorer possibly impact devices buffer_overflow ios
Topic #2: xss php cross_site_scripting script parameter inject cisco execute bug commands
Topic #3: adobe_air sdk linux windows code_execution adobe flash_player adobe_reader acrobat kernel
Topic #4: unknown files ibm java manager read authentication request management access
```

#### 2016年の脆弱性トレンド
```
##################################################
Topics in LDA model from cve2016.txt
##################################################
Topic #0: android bug xss script linux cross_site_scripting devices inject internal cisco
Topic #1: ibm acrobat adobe_reader dc windows code_execution denial_of_service cross_site_scripting bypass devices
Topic #2: access confidentiality manager integrity files bypass process android http malicious
Topic #3: denial_of_service code_execution crash impact buffer_overflow possibly discovered ios affected site
Topic #4: windows sp1 sp2 privileges php out_of_bounds gain leveraging gold read
```

#### 2017年の脆弱性トレンド

#### 2018年の脆弱性トレンド

## 5.5. おわりに

## 5.5. 動作条件
 * Python 3.6.1（Anaconda3）
 * pandas 0.20.3
 * scikit-learn 0.19.0
